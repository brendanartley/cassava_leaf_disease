{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re, math, os, cv2, random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom PIL import Image ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"myList = os.listdir('../input/cassava-leaf-disease-classification')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Notebooks that were a help\n\n\n- [cdeotte's How to Create TFrecords](https://www.kaggle.com/cdeotte/how-to-create-tfrecords)\n- [dimitreoliveira's CLD Notebook](https://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-stratified-tfrecords-256x256)\n- [TF Docs](https://www.tensorflow.org/tutorials/load_data/tfrecord)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#setting seeds for reproducability\nSEED = 3141\n\ndef seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything(SEED)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2020\n# PATH_TO_IMG = '../input/cassava-leaf-disease-classification/train_images/'\n# IMG_PATH = '../input/cassava-leaf-disease-classification/train_images'\n\n# train_df = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n# print(\"train_images: {}\".format(train_df.shape[0]))\n# train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merged 2019 + 2020 data\n\nPATH_TO_IMG = '../input/cassava-leaf-disease-merged/train/'\nIMG_PATH = '../input/cassava-leaf-disease-merged/train'\n\ntrain_df = pd.read_csv('../input/cassava-leaf-disease-merged/merged.csv')\nprint(\"train_images: {}\".format(train_df.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test: Removing Noisy Images\n\n- After training a respectable model to 0.883 LB accuracy I used this model to view the each prediction made on the validation dataset. It might be beneficial to remove some outliers/really noisy image in order to make our model more predictive on unseen data.\n\n- Another interesting solution could be to replace some of what the model think to be wrong labels with the predicted label. Testing out that solution to see if it helps?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ni_df = pd.read_csv('../input/cld-noisy-labels/submission.csv')\n# ni_df = ni_df.sort_values('confidence') #sorting by prediction confidence\n\n# #reeplacing wrong labels with an argmax of over 0.80\n# x = ni_df.query('label != pred_label and confidence > 0.85')\n# x = x.reset_index()#getting incorrect preds with high confidence\n\n# for pair in x[['index','pred_label']].values:\n#     train_df.loc[pair[0],'label'] = pair[1]\n\n# train_df = train_df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Experimenting which parts of the data it would be best to remove.\n\n- Test 1: 100 highest + 100 lowest prediction confidence\n- Test 2: 200 highest prediction confidence\n- Test 3: 200 lowest prediction confidence"},{"metadata":{},"cell_type":"markdown","source":"### TFrecord Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def _bytes_feature(value):\n    #Returns a bytes_list from a string / byte.\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    #Returns a float_list from a float / double.\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    #Returns an int64_list from a bool / enum / int / uint.\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The cell below is how we serialize each image, and will change based on the features that we want to encode in the tfrecord and their respective data_types."},{"metadata":{"trusted":true},"cell_type":"code","source":"def serialize_example(image, target, image_name):\n    feature = {\n      'image': _bytes_feature(image),\n      'target': _int64_feature(target),\n      'image_name': _bytes_feature(image_name),\n      }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Parameters\n\nIf I can figure out an efficient way to split the data within the tfrecords so I created a large number of files in order to perform cross validation during training."},{"metadata":{"trusted":true},"cell_type":"code","source":"N_FILES = 50 # split images into 15 files\nNEW_HEIGHT, NEW_WIDTH = (512, 512)\nIMG_QUALITY = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stratified K-Fold\n\nWould like to try and see if oversampling minority labels will provide a boost to score."},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=N_FILES, shuffle=True, random_state=SEED)\ntrain_df['file'] = -1\n\n#folds.split is the train_test_split of stratifiedkfolding\nfor fold_n, (train_idx, val_idx) in enumerate(folds.split(train_df, train_df['label'])):\n    print('File: %s has %s samples' % (fold_n+1, len(val_idx)))\n    train_df['file'].loc[val_idx] = fold_n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.to_csv('train.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Writing to TFrecords\n\nI made two functions that write to tfrecords here. \n\n1. Resizes all the images from 600x800 to 512x512 (smushes images)\n\n2. Center-crops all the images to 512x512\n\nThe center-cropped images seem to do better in this case\n\n"},{"metadata":{},"cell_type":"markdown","source":"#### Option 1: Resize"},{"metadata":{"trusted":true},"cell_type":"code","source":"for tfrec_num in range(N_FILES):\n    print('\\nWriting TFRecord %i of %i...'%(tfrec_num, N_FILES))\n    samples = train_df[train_df['file'] == tfrec_num]\n    n_samples = len(samples)\n    print(f'{n_samples} samples')\n    with tf.io.TFRecordWriter('Id_train%.2i-%i.tfrec'%(tfrec_num, n_samples)) as writer:\n        for row in samples.itertuples():\n            label = row.label\n            image_name = row.image_id\n            img_path = f'{PATH_TO_IMG}{image_name}'\n            \n            img = cv2.imread(img_path)\n            img = cv2.resize(img, (NEW_HEIGHT, NEW_WIDTH))\n            img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, IMG_QUALITY))[1].tostring()\n            \n            example = serialize_example(img, label, str.encode(image_name))\n            writer.write(example)\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Option 2: Center Crop\n\nI am using both PIL framework and openCV to manipulate and encode the images. \n\nHere is a discussion which I used to help transfer images between both packages. --> [PIL to CV Discussion](https://stackoverflow.com/questions/14134892/convert-image-from-pil-to-opencv-format)\n\nI think version three had BGR imgs rather than RGB. \n\nNOTE: testing to see wether the BGR to RGB had an effect on submission files. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# for tfrec_num in range(N_FILES):\n#     print('\\nWriting TFRecord %i of %i...'%(tfrec_num, N_FILES))\n#     samples = train_df[train_df['file'] == tfrec_num]\n#     n_samples = len(samples)\n#     print(f'{n_samples} samples')\n#     with tf.io.TFRecordWriter('Id_train%.2i-%i.tfrec'%(tfrec_num, n_samples)) as writer:\n#         for row in samples.itertuples():\n#             label = row.label\n#             image_name = row.image_id\n#             img_path = f'{PATH_TO_IMG}{image_name}'\n#             img = Image.open(img_path) #opening with PIL image to center-crop photo\n            \n#             #center-crop image\n#             width, height = img.size   # Get dimensions\n#             left = (width - NEW_WIDTH)/2\n#             top = (height - NEW_HEIGHT)/2\n#             right = (width + NEW_WIDTH)/2\n#             bottom = (height + NEW_HEIGHT)/2\n#             img = img.crop((left, top, right, bottom))\n            \n#             #converting to np.array\n#             open_cv_image = np.array(img)\n#             open_cv_image = open_cv_image[:, :, ::-1].copy() #when going from PIL to CV2 change BGR to RGB\n            \n#             #using cv2 package to encode image\n#             img = cv2.imencode('.jpg', open_cv_image, (cv2.IMWRITE_JPEG_QUALITY, IMG_QUALITY))[1].tostring()\n            \n#             example = serialize_example(img, label, str.encode(image_name))\n#             writer.write(example)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Option 3 Center-Crop Merged Data\n\nThe images from the 2019 data are different shapes and sizes.\n\nWe have to take into account that we cant center crop some of the images that are less than 512x512, and in these cases we can resize these images."},{"metadata":{"trusted":true},"cell_type":"code","source":"# for tfrec_num in range(N_FILES):\n#     print('\\nWriting TFRecord %i of %i...'%(tfrec_num, N_FILES))\n#     samples = train_df[train_df['file'] == tfrec_num]\n#     n_samples = len(samples)\n#     print(f'{n_samples} samples')\n#     with tf.io.TFRecordWriter('Id_train%.2i-%i.tfrec'%(tfrec_num, n_samples)) as writer:\n#         for row in samples.itertuples():\n#             label = row.label\n#             image_name = row.image_id\n#             img_path = f'{PATH_TO_IMG}{image_name}'\n#             img = Image.open(img_path) #opening with PIL image to center-crop photo\n            \n#             if img.size[0] >= 512 and img.size[1] >= 512:\n#                 #center-crop image\n#                 width, height = img.size   # Get dimensions\n#                 left = (width - NEW_WIDTH)/2\n#                 top = (height - NEW_HEIGHT)/2\n#                 right = (width + NEW_WIDTH)/2\n#                 bottom = (height + NEW_HEIGHT)/2\n#                 img = img.crop((left, top, right, bottom))\n               \n#             else:\n#                 img = img.resize((NEW_WIDTH, NEW_HEIGHT))\n            \n#             #converting to np.array\n#             open_cv_image = np.array(img)\n#             open_cv_image = open_cv_image[:, :, ::-1].copy() #when going from PIL to CV2 change BGR to RGB\n            \n#             #using cv2 package to encode image\n#             img = cv2.imencode('.jpg', open_cv_image, (cv2.IMWRITE_JPEG_QUALITY, IMG_QUALITY))[1].tostring()\n            \n#             example = serialize_example(img, label, str.encode(image_name))\n#             writer.write(example)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}