{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.system('pip install /kaggle/input/kerasapplications -q')\nos.system('pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps')\n\nfrom efficientnet.tfkeras import EfficientNetB4","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, json, cv2, math, re\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold\nimport random\n\n#model imports (keras/tensorflow)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras import layers, models\n# from tensorflow.keras.applications import EfficientNetB0\nfrom keras.optimizers import Adam\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport tensorflow.keras.backend as K\n#from tensorflow.keras.applications import ResNet50\n\nfrom kaggle_datasets import KaggleDatasets\nfrom functools import partial\n\nprint(\"Tensorflow version \" + tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"WORK_DIR = '../input/cassava-leaf-disease-classification'\nTARGET_SIZE = 512","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a few options for model submits below. There are multiple variations due to various model blending techniques. "},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# single model submit. NOTE: compile = false for models with custom loss functions\n# model = keras.models.load_model('../input/cldmanualweights/EffNet_untrained_TPU_model (1).h5', compile=False)\n# model.load_weights('../input/cldmanualweights/Effnet_TPU_Model_best_weights.h5')\n\n#two_fold\n# model_0 = keras.models.load_model('../input/cldbestsinglemodels/Archive/0.888 effnet b3 submit 54/EffNetB3_untrained_TPU_model (7).h5', compile = False)\n# model_1 = keras.models.load_model('../input/cldbestsinglemodels/Archive/0.888 v58/EffNetB3_untrained_TPU_model (7).h5', compile = False)\n\n# model_0.load_weights('../input/cldbestsinglemodels/Archive/0.888 effnet b3 submit 54/EffNetB3_TPU_Model_best_weights (7).h5')\n# model_1.load_weights('../input/cldbestsinglemodels/Archive/0.888 v58/EffNetB3_TPU_Model_best_weights (7).h5')\n\n#five_fold\nmodel_0 = keras.models.load_model('../input/cldmanualweights/EffNet_untrained_TPU_model.h5', compile = False)\nmodel_1 = keras.models.load_model('../input/cldmanualweights/EffNet_untrained_TPU_model.h5', compile = False)\nmodel_2 = keras.models.load_model('../input/cldmanualweights/EffNet_untrained_TPU_model.h5', compile = False)\nmodel_3 = keras.models.load_model('../input/cldmanualweights/EffNet_untrained_TPU_model.h5', compile = False)\nmodel_4 = keras.models.load_model('../input/cldmanualweights/EffNet_untrained_TPU_model.h5', compile = False)\n\nmodel_0.load_weights('../input/cldmanualweights/Model_0_best_weights.h5')\nmodel_1.load_weights('../input/cldmanualweights/Model_1_best_weights.h5')\nmodel_2.load_weights('../input/cldmanualweights/Model_2_best_weights.h5')\nmodel_3.load_weights('../input/cldmanualweights/Model_3_best_weights.h5')\nmodel_4.load_weights('../input/cldmanualweights/Model_4_best_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\nsample_submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Variables/Notes\n\n- Need to make sure how to center crop the test_images on submission or resizing based on how the model was trained\n- Also need to make sure I am normalizing the pixels the same way in Test and Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"NEW_WIDTH = 512\nNEW_HEIGHT = 512\nwidth = 800\nheight = 600\nleft = (width - NEW_WIDTH)/2\ntop = (height - NEW_HEIGHT)/2\nright = (width + NEW_WIDTH)/2\nbottom = (height + NEW_HEIGHT)/2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making Prediction w/ Single Model\n\n- LB: 0.887 effnetB3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# #making preds on all the test_images\n# preds = []\n\n# for image_id in sample_submission.image_id:\n#     image = Image.open(os.path.join(WORK_DIR,  \"test_images\", image_id))\n#     image = image.crop((left, top, right, bottom))  \n#     image = np.expand_dims(image, axis = 0)\n#     image = image / 255 #normalizing pixel vals before predicting\n#     image[0,:,:,0] = (image[0,:,:,0] - 0.4303)/ 0.2142 #TEST\n#     image[0,:,:,1] = (image[0,:,:,1] - 0.4967)/ 0.2191 #TEST\n#     image[0,:,:,2] = (image[0,:,:,2] - 0.3134)/ 0.1954 #TEST\n#     preds.append(np.argmax(model.predict(image)))\n\n# sample_submission['label'] = preds\n\n# sample_submission.to_csv('submission.csv', index = False)\n\n# sample_submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making Predictions w/ Highest Confidence Sum\n\n- LB: 0.881 w/ cldfiveweights v1"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npreds = []\n\nfor image_id in sample_submission.image_id:\n    image = Image.open(os.path.join(WORK_DIR,  \"test_images\", image_id))\n    image = image.resize((512, 512), Image.ANTIALIAS)\n    image = np.expand_dims(image, axis = 0)\n    image = image / 255 #normalizing pixel vals before predicting\n    image[0,:,:,0] = (image[0,:,:,0] - 0.4303)/ 0.2142 #TEST\n    image[0,:,:,1] = (image[0,:,:,1] - 0.4967)/ 0.2191 #TEST\n    image[0,:,:,2] = (image[0,:,:,2] - 0.3134)/ 0.1954 #TEST\n    \n    model_0_pred = model_0.predict(image)\n    model_1_pred = model_1.predict(image)\n    model_2_pred = model_2.predict(image)\n    model_3_pred = model_3.predict(image)\n    model_4_pred = model_4.predict(image)\n    \n    all_preds = (model_0_pred + model_1_pred + model_2_pred + model_3_pred + model_4_pred)\n    preds.append(np.argmax(all_preds))\n    \nsample_submission['label'] = preds\n\nsample_submission.to_csv('submission.csv', index = False)\n\nsample_submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making Predictions w/ Highest Pred Confidence\n\n- LB: 0.888 w/ (CLD Best Models (0.883 + 0.881)\n\nI think this submission type will be handy if I use more than model type (ie. resnet + effnet)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# preds = []\n\n# for image_id in sample_submission.image_id:\n#     image = Image.open(os.path.join(WORK_DIR,  \"test_images\", image_id))\n#     image = image.crop((left, top, right, bottom))  \n#     image = np.expand_dims(image, axis = 0)\n#     image = image / 255 #normalizing pixel vals before predicting\n#     image[0,:,:,0] = (image[0,:,:,0] - 0.4303)/ 0.2142 #TEST\n#     image[0,:,:,1] = (image[0,:,:,1] - 0.4967)/ 0.2191 #TEST\n#     image[0,:,:,2] = (image[0,:,:,2] - 0.3134)/ 0.1954 #TEST\n    \n#     model_0_pred = model_0.predict(image)\n#     model_1_pred = model_1.predict(image)\n#     model_2_pred = model_2.predict(image)\n#     model_3_pred = model_3.predict(image)\n#     model_4_pred = model_4.predict(image)\n    \n#     highest_confidence = 0\n#     preds_list = [model_0_pred, model_1_pred, model_2_pred, model_3_pred, model_4_pred]\n\n#     for pred_group in preds_list:\n#         if highest_confidence == 0:\n#             highest_confidence = float(np.min(pred_group))\n\n#         if float(np.max(pred_group)) > highest_confidence:\n#             highest_confidence = float(np.max(pred_group))\n#             pred = np.argmax(pred_group)\n    \n#     preds.append(pred)\n    \n# sample_submission['label'] = preds\n\n# sample_submission.to_csv('submission.csv', index = False)\n\n# sample_submission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}